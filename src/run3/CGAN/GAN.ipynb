{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "from sys import path, stdout\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "\n",
    "path.append(\"/home/leandrosantos/IC-AutoEncoder/\")\n",
    "path.append(\"/home/leandrosantos/IC-AutoEncoder/modules/\")\n",
    "path.append(\"/home/leandrosantos/IC-AutoEncoder/src/modules/\")\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from modules.misc import ssim_metric\n",
    "from modules.ImageMetrics.metrics import three_ssim, psnrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching dataset\n",
    "\n",
    "from modules.DataMod import DataSet\n",
    "import cupy\n",
    "\n",
    "cifar, tiny, noised_dataset = DataSet(), DataSet(), DataSet()\n",
    "\n",
    "cifar.load_rafael_cifar_10_noise_data()\n",
    "tiny.load_rafael_tinyImagenet_64x64_noise_data()\n",
    "print(\"Cifar and tiny loaded.\")\n",
    "\n",
    "noised_dataset.load_cifar_and_tiny(cifar, tiny)\n",
    "noised_dataset.add_gaussian_noise(dist_normal = 0.3) # adds gaussian noise\n",
    "print(\"Dataset created.\")\n",
    "\n",
    "cupy.get_default_memory_pool().free_all_blocks()\n",
    "cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "del cifar, tiny\n",
    "\n",
    "x_test = noised_dataset.x_test\n",
    "y_test = noised_dataset.y_test / 255\n",
    "x_train = noised_dataset.x_train\n",
    "y_train = noised_dataset.y_train / 255\n",
    "\n",
    "del noised_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "columns = 2\n",
    "rows = 6\n",
    "\n",
    "magic_number = [rd.randint(0, x_train.shape[0]-1) for x in range(rows)]\n",
    "\n",
    "plt.subplot(rows, columns, 1)\n",
    "plt.title(\"normal\")\n",
    "plt.subplot(rows, columns, 2)\n",
    "plt.title(\"0.3 std dev\")\n",
    "\n",
    "for idx in range(rows):\n",
    "    plt.subplot(rows, columns, columns*idx + 1)\n",
    "    plt.imshow(y_train[magic_number[idx]], cmap='gray')\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(rows, columns, columns*idx + 2)\n",
    "    plt.imshow(x_train[magic_number[idx]], cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "\n",
    "LEARNING_RATE = 0.00005\n",
    "BATCH_SIZE = 16\n",
    "IMG_SHAPE = (64, 64, 1)\n",
    "\n",
    "N_EPOCHS = 500\n",
    "CURRENT_EPOCH = 0\n",
    "PATIENCE_LIMIT = 10\n",
    "\n",
    "ADVERSARIAL_LOSS_FACTOR = 1.0\n",
    "PIXEL_LOSS_FACTOR = 1.0\n",
    "SMOOTH_LOSS_FACTOR = 1.0\n",
    "\n",
    "N_CRITIC = 1\n",
    "SAVE_EVERY_N_EPOCH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(45)\n",
    "y_train_batches = tf.random.shuffle(y_train)\n",
    "tf.random.set_seed(45)\n",
    "x_train_batches = tf.random.shuffle(x_train)\n",
    "\n",
    "num_train_batches = int(x_train.shape[0]/BATCH_SIZE)\n",
    "y_train_batches = np.split(y_train_batches, num_train_batches)\n",
    "x_train_batches = np.split(x_train_batches, num_train_batches)\n",
    "\n",
    "val_size = int(len(y_test)*0.8)\n",
    "tf.random.set_seed(43)\n",
    "y_test_batches = tf.random.shuffle(y_test[:val_size])\n",
    "tf.random.set_seed(43)\n",
    "x_test_batches = tf.random.shuffle(x_test[:val_size])\n",
    "\n",
    "num_test_batches = int(x_test_batches.shape[0]/500)\n",
    "y_test_batches = np.split(y_test_batches, num_test_batches)\n",
    "x_test_batches = np.split(x_test_batches, num_test_batches)\n",
    "\n",
    "def standard_images(images):\n",
    "    for image in images:\n",
    "        image = tf.cast(tf.image.per_image_standardization(image), tf.float64)\n",
    "    \n",
    "    return images\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_batches = np.array(standard_images(x_test_batches))\n",
    "y_test_batches = np.array(standard_images(y_test_batches))\n",
    "\n",
    "x_train_batches = np.array(standard_images(x_train_batches))\n",
    "y_train_batches = np.array(standard_images(y_train_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert x_test_batches.shape == y_test_batches.shape\n",
    "assert x_train_batches.shape == y_train_batches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Input, Dropout, MaxPooling2D, UpSampling2D, Conv2DTranspose, Add, LeakyReLU\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "def generator_model(input_shape=IMG_SHAPE):\n",
    "\n",
    "    input_layer = Input(input_shape)\n",
    "\n",
    "    # First Set\n",
    "    conv1 = Conv2D(kernel_size=8, filters=64, strides=2, padding=\"same\")(input_layer)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    out_conv1 = LeakyReLU()(norm1)\n",
    "\n",
    "    conv2 = Conv2D(kernel_size=4, filters=128, strides=2, padding=\"same\")(out_conv1)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    out_conv2 = LeakyReLU()(norm2)\n",
    "\n",
    "    conv3 = Conv2D(kernel_size=4, filters=256, strides=2, padding=\"same\")(out_conv2)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    out_conv3 = LeakyReLU()(norm3)\n",
    "\n",
    "    # End of First Set\n",
    "\n",
    "    # Second Set - Residual\n",
    "    # Block 1\n",
    "    res1_conv1 = Conv2D(kernel_size=4, filters=256, strides=1, padding=\"same\")(out_conv3)\n",
    "    res1_norm1 = BatchNormalization()(res1_conv1)\n",
    "    out_res1_conv1 = LeakyReLU()(res1_norm1)\n",
    "\n",
    "    res1_conv2 = Conv2D(kernel_size=4, filters=256, strides=1, padding=\"same\")(out_res1_conv1)\n",
    "    res1_norm2 = BatchNormalization()(res1_conv2)\n",
    "    out_res1_conv2 = LeakyReLU()(res1_norm2)\n",
    "\n",
    "    out_res1 = Add()([out_res1_conv2, out_conv3])\n",
    "\n",
    "    # Block 2\n",
    "    res2_conv1 = Conv2D(kernel_size=4, filters=256, strides=1, padding=\"same\")(out_res1)\n",
    "    res2_norm1 = BatchNormalization()(res2_conv1)\n",
    "    out_res2_conv1 = LeakyReLU()(res2_norm1)\n",
    "\n",
    "    res2_conv2 = Conv2D(kernel_size=4, filters=256, strides=1, padding=\"same\")(out_res2_conv1)\n",
    "    res2_norm2 = BatchNormalization()(res2_conv2)\n",
    "    out_res2_conv2 = LeakyReLU()(res2_norm2)\n",
    "\n",
    "    out_res2 = Add()([out_res2_conv2, out_res1])\n",
    "\n",
    "    # Block 3\n",
    "    res3_conv1 = Conv2D(kernel_size=4, filters=256, strides=1, padding=\"same\")(out_res2)\n",
    "    res3_norm1 = BatchNormalization()(res3_conv1)\n",
    "    out_res3_conv1 = LeakyReLU()(res3_norm1)\n",
    "\n",
    "    res3_conv2 = Conv2D(kernel_size=4, filters=256, strides=1, padding=\"same\")(out_res3_conv1)\n",
    "    res3_norm2 = BatchNormalization()(res3_conv2)\n",
    "    out_res3_conv2 = LeakyReLU()(res3_norm2)\n",
    "\n",
    "    out_res3 = Add()([out_res3_conv2, out_res2])\n",
    "    # End of Second Set\n",
    "\n",
    "    # Third Set - Deconvolutional\n",
    "    deconv1 = Conv2DTranspose(kernel_size=4, filters=128, strides=2, padding=\"same\")(out_res3)\n",
    "    deconv1_norm1 = BatchNormalization()(deconv1)\n",
    "    deconv1_dropout = Dropout(0.5)(deconv1_norm1)\n",
    "    out_deconv1 = LeakyReLU()(deconv1_dropout)\n",
    "\n",
    "    deconv2 = Conv2DTranspose(kernel_size=4, filters=64, strides=2, padding=\"same\")(out_deconv1)\n",
    "    deconv2_norm1 = BatchNormalization()(deconv2)\n",
    "    deconv2_dropout = Dropout(0.5)(deconv2_norm1)\n",
    "    out_deconv2 = LeakyReLU()(deconv2_dropout)\n",
    "\n",
    "    out_deconv2_temp = Add()([out_deconv2, out_conv1])\n",
    "\n",
    "    deconv3 = Conv2DTranspose(kernel_size=8, filters=IMG_SHAPE[-1], strides=2, padding=\"same\")(out_deconv2_temp)\n",
    "    deconv3_norm1 = BatchNormalization()(deconv3)\n",
    "    deconv3_dropout = Dropout(0.5)(deconv3_norm1)\n",
    "    out_deconv3 = LeakyReLU()(deconv3_dropout)\n",
    "\n",
    "    out_deconv3_temp = Add()([out_deconv3, input_layer])\n",
    "    # End of Third Set\n",
    "\n",
    "    output = tf.clip_by_value(out_deconv3_temp, 0, 1)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "def discriminator_model(input_x_shape=IMG_SHAPE):\n",
    "    input_layer = Input(input_x_shape)\n",
    "\n",
    "    conv1 = Conv2D(kernel_size=8, filters=48, strides=2, padding=\"same\")(input_layer)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    out_conv1 = tf.nn.leaky_relu(norm1)\n",
    "\n",
    "    conv2 = Conv2D(kernel_size=4, filters=96, strides=2, padding=\"same\")(out_conv1)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    out_conv2 = tf.nn.leaky_relu(norm2)\n",
    "    out_conv2 = Dropout(0.2)(out_conv2)\n",
    "    \n",
    "    conv3 = Conv2D(kernel_size=4, filters=192, strides=2, padding=\"same\")(out_conv2)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    out_conv3 = tf.nn.leaky_relu(norm3)\n",
    "\n",
    "    conv4 = Conv2D(kernel_size=4, filters=384, strides=2, padding=\"same\")(out_conv3)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    out_conv4 = tf.nn.leaky_relu(norm4)\n",
    "    out_conv4 = Dropout(0.2)(out_conv4)\n",
    "    \n",
    "    conv5 = Conv2D(kernel_size=8, filters=1, strides=2, padding=\"same\")(out_conv4)\n",
    "    norm5 = BatchNormalization()(conv5)\n",
    "    out_conv5 = sigmoid(norm5)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=out_conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'GAN'\n",
    "\n",
    "OUTPUT_PATH = os.path.join('outputs', MODEL_NAME)\n",
    "TRAIN_LOGDIR = os.path.join(\"logs\", \"tensorflow\", MODEL_NAME, 'train_data') # Sets up a log directory.\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "D_optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "G_optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def get_smooth_loss(image):\n",
    "    batch_count = tf.shape(image)[0]\n",
    "    image_height = tf.shape(image)[1]\n",
    "    image_width = tf.shape(image)[2]\n",
    "\n",
    "    horizontal_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height, image_width-1,IMG_SHAPE[-1]])\n",
    "    horizontal_one_right = tf.slice(image, [0, 0, 1,0], [batch_count, image_height, image_width-1,IMG_SHAPE[-1]])\n",
    "    vertical_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height-1, image_width,IMG_SHAPE[-1]])\n",
    "    vertical_one_right = tf.slice(image, [0, 1, 0,0], [batch_count, image_height-1, image_width,IMG_SHAPE[-1]])\n",
    "    smooth_loss = tf.nn.l2_loss(horizontal_normal-horizontal_one_right)+tf.nn.l2_loss(vertical_normal-vertical_one_right)\n",
    "    return smooth_loss\n",
    "\n",
    "def get_pixel_loss(target,prediction):\n",
    "    pixel_difference = target - prediction\n",
    "    pixel_loss = tf.nn.l2_loss(pixel_difference)\n",
    "    return pixel_loss\n",
    "\n",
    "@tf.function\n",
    "def G_train_step(noised_images, real_images):\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        generated_image = tf.cast(generator([noised_images], training=True), tf.float64)\n",
    "        generated_image_pred = tf.cast(discriminator([generated_image], training=True), tf.float64)\n",
    "\n",
    "        g_loss = ADVERSARIAL_LOSS_FACTOR * -tf.reduce_mean(tf.math.log(generated_image_pred)) \\\n",
    "        + PIXEL_LOSS_FACTOR * get_pixel_loss(real_images, generated_image) \\\n",
    "        + SMOOTH_LOSS_FACTOR * get_smooth_loss(generated_image) \\\n",
    "        #+ tf.cast(SSIM_LOSS_FACTOR * tf.math.reduce_mean(1-ssim_metric(real_images, generated_image, max_val=1.0)), tf.float64)\n",
    "        #+ CROSS_ENTROPY_LOSS_FACTOR * cross_entropy(tf.ones_like(generated_image_pred), generated_image_pred)\n",
    "\n",
    "    G_gradients = gp_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    G_optimizer.apply_gradients(zip(G_gradients, generator.trainable_variables))\n",
    "    if step % 10 == 0:\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('G_loss', g_loss, step=step)\n",
    "            \n",
    "    return g_loss\n",
    "\n",
    "@tf.function\n",
    "def D_train_step(noised_images, real_images):\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        generated_image = tf.cast(generator([noised_images], training=True), tf.float64)\n",
    "        generated_image_pred = tf.cast(discriminator([generated_image], training=True), tf.float64)\n",
    "        real_image_pred = tf.cast(discriminator([real_images], training=True), tf.float64)\n",
    "\n",
    "        d_loss = -tf.reduce_mean(tf.math.log(real_image_pred) + tf.math.log(1.-generated_image_pred)) \\\n",
    "        #+ cross_entropy(tf.ones_like(generated_image_pred), generated_image_pred) \\\n",
    "        #+ cross_entropy(tf.ones_like(real_image_pred), real_image_pred)\n",
    "        \n",
    "    D_gradients = gp_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    D_optimizer.apply_gradients(zip(D_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('D_loss', tf.reduce_mean(d_loss), step=step)\n",
    "    \n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, expected_output, figure_size=(12,6), subplot=(3,6), save=True, show=False):\n",
    "    '''\n",
    "        Generate images and plot it.\n",
    "    '''\n",
    "    rows = subplot[0]\n",
    "    columns = subplot[1]\n",
    "\n",
    "    predictions = model(test_input, training=False) \n",
    "    fig, axs = plt.subplots(rows, columns, figsize=figure_size, gridspec_kw={'width_ratios':[1 for x in range(columns)], 'height_ratios':[1 for x in range(rows)]})\n",
    "    fig.subplots_adjust(top=0.4)\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            i = column\n",
    "            if row == 0:\n",
    "                # y\n",
    "                axs[row, column].set_title('GroundTruth') if i == columns//2 else None\n",
    "                axs[row, column].imshow(expected_output[i], cmap='gray')\n",
    "            elif row == 1:\n",
    "                # predict\n",
    "                axs[row, column].set_title('Output') if i == columns//2 else None\n",
    "                axs[row, column].imshow(predictions[i], cmap='gray')\n",
    "            else:\n",
    "                # x\n",
    "                axs[row, column].set_title('Input') if i == columns//2 else None\n",
    "                axs[row, column].imshow(test_input[i], cmap='gray')\n",
    "            axs[row, column].axis('off')\n",
    "    \n",
    "    ssim_out = tf.math.reduce_mean(ssim_metric(expected_output, predictions, max_val=1.))\n",
    "    #psnrb_v_out = tf.math.reduce_mean(psnrb(expected_output, predictions))\n",
    "    \n",
    "    ssim_in = tf.math.reduce_mean(ssim_metric(expected_output, test_input, max_val=1.))\n",
    "    #psnrb_v_out = tf.math.reduce_mean(psnrb(expected_output, predictions))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"ssim_input:%.5f, ssim_output: %.5f\" %(ssim_in, ssim_out), y=1)\n",
    "            \n",
    "    del fig, axs\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_generate = 7\n",
    "\n",
    "# change y_test for x_test\n",
    "magic_number = [rd.randint(0, x_test[val_size:].shape[0]-1) for x in range(num_examples_to_generate)]\n",
    "\n",
    "sample = np.array([x_test[val_size:][idx] for idx in magic_number])\n",
    "answer = np.array([y_test[val_size:][idx] for idx in magic_number])\n",
    "\n",
    "generate_and_save_images(generator, 0, sample, answer, figure_size=(12,6), subplot=(3, num_examples_to_generate), save=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\"checkpoints\", \"tensorflow\", MODEL_NAME)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator=generator,\n",
    "                           discriminator=discriminator,\n",
    "                           G_optimizer=G_optimizer,\n",
    "                           D_optimizer=D_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    latest_epoch = int(ckpt_manager.latest_checkpoint.split('-')[1])\n",
    "    CURRENT_EPOCH = latest_epoch * SAVE_EVERY_N_EPOCH\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(CURRENT_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_critic_count = 0\n",
    "D_loss = float('inf')\n",
    "G_loss = float('inf')\n",
    "\n",
    "best_val_metric = 0\n",
    "patience = 0\n",
    "\n",
    "# train until saturate\n",
    "epoch = CURRENT_EPOCH\n",
    "while epoch < N_EPOCHS+1:\n",
    "    with tqdm_notebook(total=len(y_train_batches)) as pbar:\n",
    "        for step, (training_batch, groundtruth_batch) in enumerate(zip(x_train_batches, y_train_batches)):\n",
    "            D_loss = D_train_step(training_batch, groundtruth_batch)\n",
    "            n_critic_count+=1\n",
    "            \n",
    "            if n_critic_count >= N_CRITIC:\n",
    "                G_loss = G_train_step(training_batch, groundtruth_batch)\n",
    "                n_critic_cout = 0\n",
    "            \n",
    "            images_out = generator(training_batch, training=False)\n",
    "            ssim_train_metric = tf.math.reduce_mean(ssim_metric(groundtruth_batch, images_out, max_val=1.))\n",
    "            pbar.set_description_str(\"Epoch %d/%d: \" %(epoch+1, N_EPOCHS))\n",
    "            pbar.set_postfix_str(\"G_loss: %.5f, D_loss: %.5f, ssim_metric: %.5f\" %(G_loss, D_loss, ssim_train_metric))\n",
    "            pbar.update(1)\n",
    "            #clear_output(wait=True)\n",
    "        \n",
    "        # validação\n",
    "        ssim = []\n",
    "        psnrb_v = []\n",
    "        for (x, y) in zip(x_test_batches, y_test_batches):\n",
    "            images_out = generator(x, training=False)\n",
    "\n",
    "            ssim.append(tf.math.reduce_mean(ssim_metric(y, images_out, max_val=1.)))\n",
    "            #psnrb_v.append(tf.math.reduce_mean(psnrb(y, images_out)))\n",
    "            \n",
    "        with file_writer.as_default():\n",
    "            #tf.summary.scalar('psnrb_val', tf.reduce_mean(psnrb_v), step=step)\n",
    "            tf.summary.scalar('ssim_val', tf.reduce_mean(ssim), step=step)\n",
    "        \n",
    "        pbar.set_postfix_str(\"G_loss_train: %.5f, D_loss_train: %.5f, ssim_metric_train: %.5f, ssim_metric_val: %.5f\" %(G_loss, D_loss, ssim_train_metric, tf.reduce_mean(ssim)))\n",
    "\n",
    "    # se melhorou, salva e continua o treino\n",
    "    if tf.reduce_mean(ssim) >= best_val_metric:\n",
    "        patience = 0\n",
    "        best_val_metric = tf.reduce_mean(ssim)\n",
    "\n",
    "        if epoch % SAVE_EVERY_N_EPOCH == 0:\n",
    "            # only save se improved\n",
    "            ckpt_save_path = ckpt_manager.save()\n",
    "            generate_and_save_images(generator, epoch, sample, answer, figure_size=(12,6), subplot=(3,num_examples_to_generate), save=True)\n",
    "    else:\n",
    "        # senão enche a paciência\n",
    "        patience += 1\n",
    "\n",
    "    if patience == PATIENCE_LIMIT:\n",
    "        break\n",
    "    epoch+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim = []\n",
    "psnrb_v = []\n",
    "for (x, y) in zip(np.split(x_test[val_size:], 20), np.split(y_test[val_size:], 20)):\n",
    "    images_out = generator(x, training=False)\n",
    "\n",
    "    ssim.append(tf.math.reduce_mean(ssim_metric(y, images_out, max_val=1.)))\n",
    "    psnrb_v.append(tf.math.reduce_mean(psnrb(y, images_out)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(psnrb_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reduce_mean(ssim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
