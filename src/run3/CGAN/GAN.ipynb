{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ\n",
    "\n",
    "environ['CUDA_VISIBLE_DEVICEs'] = \"0\"\n",
    "from sys import path, stdout\n",
    "import os\n",
    "\n",
    "path.append(\"/home/leandrosantos/IC-AutoEncoder/\")\n",
    "path.append(\"/home/leandrosantos/IC-AutoEncoder/modules/\")\n",
    "path.append(\"/home/leandrosantos/IC-AutoEncoder/src/modules/\")\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "import random as rd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from modules.misc import ssim_metric\n",
    "from modules.ImageMetrics.metrics import three_ssim, psnrb\n",
    "\n",
    "from libs.vgg16 import *\n",
    "from libs import vgg16\n",
    "from libs.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "y_test = x_test\n",
    "y_train = x_train\n",
    "\n",
    "# adding noise \n",
    "num_chuncks = 100\n",
    "chunck_size = int(len(x_train)/num_chuncks)\n",
    "x_train_gpu = np.zeros(y_train[:chunck_size].shape)\n",
    "x_train = np.zeros(y_train.shape)\n",
    "with tqdm(total=num_chuncks) as pbar:\n",
    "    for it in range(num_chuncks):\n",
    "        start = it*chunck_size\n",
    "        end = (it+1)*chunck_size\n",
    "        \n",
    "        x_train_gpu = y_train[start: end].astype('float64') / 255\n",
    "        \n",
    "        noise = tf.random.normal(x_train_gpu.shape, mean=0, stddev=0.3)\n",
    "\n",
    "        x_train_gpu += noise\n",
    "        del noise\n",
    "        x_train_gpu = tf.clip_by_value(x_train_gpu, 0, 1)\n",
    "        x_train[start : end] = x_train_gpu.numpy()\n",
    "        del x_train_gpu\n",
    "        pbar.update(1)\n",
    "\n",
    "num_chuncks = 50\n",
    "chunck_size = int(len(x_test)/num_chuncks)\n",
    "x_test_gpu = np.zeros(y_test[:chunck_size].shape)\n",
    "x_test = np.zeros(y_test.shape)\n",
    "with tqdm(total=num_chuncks) as pbar:\n",
    "    for it in range(num_chuncks):\n",
    "        start = it*chunck_size\n",
    "        end = (it+1)*chunck_size\n",
    "        \n",
    "        x_test_gpu = y_test[start: end].astype('float64') / 255\n",
    "        \n",
    "        noise = tf.random.normal(x_test_gpu.shape, mean=0, stddev=0.3)\n",
    "\n",
    "        x_test_gpu += noise\n",
    "        del noise\n",
    "        x_test_gpu = tf.clip_by_value(x_test_gpu, 0, 1)\n",
    "        x_test[start : end] = x_test_gpu.numpy()\n",
    "        del x_test_gpu\n",
    "        pbar.update(1)\n",
    "        \n",
    "x_test = tf.cast(x_test, tf.float64)\n",
    "y_test = tf.cast(y_test, tf.float64) / 255\n",
    "x_train = tf.cast(x_train, tf.float64)\n",
    "y_train = tf.cast(y_train, tf.float64) / 255\n",
    "\n",
    "assert x_test.shape == y_test.shape and x_train.shape == y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "columns = 2\n",
    "rows = 6\n",
    "\n",
    "magic_number = [rd.randint(0, x_train.shape[0]-1) for x in range(rows)]\n",
    "\n",
    "plt.subplot(rows, columns, 1)\n",
    "plt.title(\"normal\")\n",
    "plt.subplot(rows, columns, 2)\n",
    "plt.title(\"0.3 std dev\")\n",
    "\n",
    "for idx in range(rows):\n",
    "    plt.subplot(rows, columns, columns*idx + 1)\n",
    "    plt.imshow(y_train[magic_number[idx]])\n",
    "    plt.axis(\"off\")\n",
    "    plt.subplot(rows, columns, columns*idx + 2)\n",
    "    plt.imshow(x_train[magic_number[idx]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters \n",
    "\n",
    "LEARNING_RATE = 0.002\n",
    "BATCH_SIZE = 25\n",
    "BATCH_SHAPE = [BATCH_SIZE, 32, 32, 3]\n",
    "SKIP_STEP = 10\n",
    "N_EPOCHS = 500\n",
    "ADVERSARIAL_LOSS_FACTOR = 0.5\n",
    "PIXEL_LOSS_FACTOR = 1.0\n",
    "STYLE_LOSS_FACTOR = 1.0\n",
    "SMOOTH_LOSS_FACTOR = 1.0\n",
    "N_CRITIC = 5\n",
    "\n",
    "SAVE_EVERY_N_EPOCH = 10\n",
    "VAL_EVERY_N_STEPS = 50\n",
    "CURRENT_EPOCH = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_batches = int(x_train.shape[0]/BATCH_SIZE)\n",
    "y_train_batches = np.split(y_train, num_train_batches)\n",
    "x_train_batches = np.split(x_train, num_train_batches)\n",
    "\n",
    "num_test_batches = int(x_test.shape[0]/BATCH_SIZE)\n",
    "y_test_batches = np.split(y_test, num_train_batches)\n",
    "x_test_batches = np.split(x_test, num_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_batches = tf.cast(tf.image.per_image_standardization(x_test_batches), tf.float64)#tf.map_fn(lambda img: tf.cast(tf.image.per_image_standardization(img), tf.float64), x_test_batches)\n",
    "y_test_batches = #tf.map_fn(lambda img: tf.cast(tf.image.per_image_standardization(img), tf.float64), y_test_batches)\n",
    "\n",
    "x_train_batches = tf.map_fn(lambda img: tf.cast(tf.image.per_image_standardization(img), tf.float64), x_train_batches)\n",
    "y_train_batches = tf.map_fn(lambda img: tf.cast(tf.image.per_image_standardization(img), tf.float64), y_train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Input #, LeakyReLU\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_model(input_shape=(32, 32, 3)):\n",
    "\n",
    "    input_layer = Input(input_shape)\n",
    "\n",
    "    # First Set\n",
    "    conv1 = Conv2D(kernel_size=4, filters=32, strides=1, padding=\"same\")(input_layer)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    out_conv1 = tf.nn.leaky_relu(norm1)\n",
    "\n",
    "    conv2 = Conv2D(kernel_size=3, filters=64, strides=1, padding=\"same\")(out_conv1)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    out_conv2 = tf.nn.leaky_relu(norm2)\n",
    "\n",
    "    conv3 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_conv2)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    out_conv3 = tf.nn.leaky_relu(norm3)\n",
    "    # End of First Set\n",
    "\n",
    "    # Second Set - Residual\n",
    "    # Block 1\n",
    "    res1_conv1 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_conv3)\n",
    "    res1_norm1 = BatchNormalization()(res1_conv1)\n",
    "    out_res1_conv1 = tf.nn.leaky_relu(res1_norm1)\n",
    "\n",
    "    res1_conv2 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_res1_conv1)\n",
    "    res1_norm2 = BatchNormalization()(res1_conv2)\n",
    "    out_res1_conv2 = tf.nn.leaky_relu(res1_norm2)\n",
    "\n",
    "    out_res1 = out_res1_conv2 + out_conv3\n",
    "\n",
    "    # Block 2\n",
    "    res2_conv1 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_res1)\n",
    "    res2_norm1 = BatchNormalization()(conv1)\n",
    "    out_res2_conv1 = tf.nn.leaky_relu(norm1)\n",
    "\n",
    "    res2_conv2 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_res2_conv1)\n",
    "    res2_norm2 = BatchNormalization()(res2_conv2)\n",
    "    out_res2_conv2 = tf.nn.leaky_relu(res2_norm2)\n",
    "\n",
    "    out_res2 = out_res2_conv2 + out_res1\n",
    "\n",
    "    # Block 3\n",
    "    res3_conv1 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_res2)\n",
    "    res3_norm1 = BatchNormalization()(res3_conv1)\n",
    "    out_res3_conv1 = tf.nn.leaky_relu(res3_norm1)\n",
    "\n",
    "    res3_conv2 = Conv2D(kernel_size=3, filters=128, strides=1, padding=\"same\")(out_res3_conv1)\n",
    "    res3_norm2 = BatchNormalization()(res3_conv2)\n",
    "    out_res3_conv2 = tf.nn.leaky_relu(res3_norm2)\n",
    "\n",
    "    out_res3 = out_res3_conv2 + out_res2\n",
    "    # End of Second Set\n",
    "\n",
    "\n",
    "    def resize_deconvolution_layer(input_tensor, new_shape, scope_name):\n",
    "        with tf.compat.v1.variable_scope(scope_name, reuse=True):\n",
    "            output = tf.image.resize(input_tensor, (new_shape[1], new_shape[2]))\n",
    "            output, unused_weights = conv_layer(output, 3, new_shape[3]*2, new_shape[3], 1, scope_name+\"_deconv\")\n",
    "            return output\n",
    "\n",
    "    def deconvolution_layer(input_tensor, new_shape, scope_name):\n",
    "        return resize_deconvolution_layer(input_tensor, new_shape, scope_name)\n",
    "    \n",
    "    # Third Set - Deconvolutional\n",
    "\n",
    "    deconv1 = Conv2D(kernel_size=3, filters=64, strides=1, padding=\"same\")(out_res3)\n",
    "    deconv1_norm1 = BatchNormalization()(deconv1)\n",
    "    out_deconv1 = tf.nn.leaky_relu(deconv1_norm1)\n",
    "\n",
    "    deconv2 = Conv2D(kernel_size=3, filters=32, strides=1, padding=\"same\")(out_deconv1)\n",
    "    deconv2_norm1 = BatchNormalization()(deconv2)\n",
    "    out_deconv2 = tf.nn.leaky_relu(deconv2_norm1)\n",
    "\n",
    "    out_deconv2_temp = out_deconv2 + conv1\n",
    "\n",
    "    deconv3 = Conv2D(kernel_size=4, filters=3, strides=1, padding=\"same\")(out_deconv2_temp)\n",
    "    deconv3_norm1 = BatchNormalization()(deconv3)\n",
    "    out_deconv3 = tf.nn.tanh(deconv3_norm1)\n",
    "\n",
    "    out_deconv3_temp = out_deconv3 + input_layer\n",
    "    # End of Third Set\n",
    "    \n",
    "    output =  tf.clip_by_value(out_deconv3_temp, 0, 1)\n",
    "\n",
    "    return Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "\n",
    "\n",
    "def discriminator_model(input_x_shape=(32, 32, 3)):\n",
    "    input_layer = Input(input_x_shape)\n",
    "\n",
    "    conv1 = Conv2D(kernel_size=4, filters=48, strides=2, padding=\"same\")(input_layer)\n",
    "    norm1 = BatchNormalization()(conv1)\n",
    "    out_conv1 = tf.nn.leaky_relu(norm1)\n",
    "\n",
    "    conv2 = Conv2D(kernel_size=4, filters=96, strides=2, padding=\"same\")(out_conv1)\n",
    "    norm2 = BatchNormalization()(conv2)\n",
    "    out_conv2 = tf.nn.leaky_relu(norm2)\n",
    "\n",
    "    conv3 = Conv2D(kernel_size=4, filters=192, strides=2, padding=\"same\")(out_conv2)\n",
    "    norm3 = BatchNormalization()(conv3)\n",
    "    out_conv3 = tf.nn.leaky_relu(norm3)\n",
    "\n",
    "    conv4 = Conv2D(kernel_size=4, filters=384, strides=2, padding=\"same\")(out_conv3)\n",
    "    norm4 = BatchNormalization()(conv4)\n",
    "    out_conv4 = tf.nn.leaky_relu(norm4)\n",
    "\n",
    "    conv5 = Conv2D(kernel_size=4, filters=1, strides=2, padding=\"same\")(out_conv4)\n",
    "    norm5 = BatchNormalization()(conv5)\n",
    "    out_conv5 = sigmoid(norm5)\n",
    "    \n",
    "    return Model(inputs=input_layer, outputs=out_conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'GAN'\n",
    "\n",
    "OUTPUT_PATH = os.path.join('outputs', MODEL_NAME)\n",
    "TRAIN_LOGDIR = os.path.join(\"logs\", \"tensorflow\", MODEL_NAME, 'train_data') # Sets up a log directory.\n",
    "if not os.path.exists(OUTPUT_PATH):\n",
    "    os.makedirs(OUTPUT_PATH)\n",
    "\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine cross_entropy loss to generator and discriminator\n",
    "'''cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "generated_image = tf.cast(generator([x_train_batches[0]], training=True), tf.float64)\n",
    "generated_image_pred = tf.cast(discriminator([generated_image], training=True), tf.float64)\n",
    "#real_image_pred = tf.cast(discriminator([real_images], training=True), tf.float64)\n",
    "\n",
    "cross_entropy(tf.ones_like(generated_image_pred), generated_image_pred)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "D_optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "G_optimizer = Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "'''\n",
    "def get_style_layer_vgg16(image):\n",
    "    net = vgg16.get_vgg_model()\n",
    "    style_layer = 'conv2_2/conv2_2:0'\n",
    "    feature_transformed_image = tf.import_graph_def(\n",
    "        net['graph_def'],\n",
    "        name='vgg',\n",
    "        input_map={'images:0': tf.cast(image, tf.float64)},return_elements=[style_layer])\n",
    "    feature_transformed_image = (feature_transformed_image[0])\n",
    "    return feature_transformed_image\n",
    "'''\n",
    "\n",
    "def get_style_loss(target,prediction):\n",
    "    feature_transformed_target = get_style_layer_vgg16(target)\n",
    "    feature_transformed_prediction = get_style_layer_vgg16(prediction)\n",
    "    feature_count = tf.shape(feature_transformed_target)[3]\n",
    "    style_loss = tf.reduce_sum(tf.square(feature_transformed_target-feature_transformed_prediction))\n",
    "    style_loss = style_loss/tf.cast(feature_count, tf.float64)\n",
    "    return style_loss\n",
    "\n",
    "def get_smooth_loss(image):\n",
    "    batch_count = tf.shape(image)[0]\n",
    "    image_height = tf.shape(image)[1]\n",
    "    image_width = tf.shape(image)[2]\n",
    "\n",
    "    horizontal_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height, image_width-1,3])\n",
    "    horizontal_one_right = tf.slice(image, [0, 0, 1,0], [batch_count, image_height, image_width-1,3])\n",
    "    vertical_normal = tf.slice(image, [0, 0, 0,0], [batch_count, image_height-1, image_width,3])\n",
    "    vertical_one_right = tf.slice(image, [0, 1, 0,0], [batch_count, image_height-1, image_width,3])\n",
    "    smooth_loss = tf.nn.l2_loss(horizontal_normal-horizontal_one_right)+tf.nn.l2_loss(vertical_normal-vertical_one_right)\n",
    "    return smooth_loss\n",
    "\n",
    "def get_pixel_loss(target,prediction):\n",
    "    pixel_difference = target - prediction\n",
    "    pixel_loss = tf.nn.l2_loss(pixel_difference)\n",
    "    return pixel_loss\n",
    "\n",
    "@tf.function\n",
    "def G_train_step(noised_images, real_images):\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        generated_image = tf.cast(generator([noised_images], training=True), tf.float64)\n",
    "        generated_image_pred = tf.cast(discriminator([generated_image], training=True), tf.float64)\n",
    "\n",
    "        g_loss = ADVERSARIAL_LOSS_FACTOR * -tf.reduce_mean(tf.math.log(generated_image_pred)) + PIXEL_LOSS_FACTOR * get_pixel_loss(real_images, generated_image) \\\n",
    "            + SMOOTH_LOSS_FACTOR * get_smooth_loss(generated_image) #+ STYLE_LOSS_FACTOR * get_style_loss(real_in_bgr, generated_in_bgr)\n",
    "    \n",
    "    G_gradients = gp_tape.gradient(g_loss, generator.trainable_variables)\n",
    "    G_optimizer.apply_gradients(zip(G_gradients, generator.trainable_variables))\n",
    "    if step % 10 == 0:\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('G_loss', g_loss, step=step)\n",
    "            \n",
    "    return g_loss\n",
    "\n",
    "@tf.function\n",
    "def D_train_step(noised_images, real_images):\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        generated_image = tf.cast(generator([noised_images], training=True), tf.float64)\n",
    "        generated_image_pred = tf.cast(discriminator([generated_image], training=True), tf.float64)\n",
    "        real_image_pred = tf.cast(discriminator([real_images], training=True), tf.float64)\n",
    "\n",
    "        d_loss = -tf.reduce_mean(tf.math.log(real_image_pred) + tf.math.log(1.-generated_image_pred))\n",
    "        \n",
    "    D_gradients = gp_tape.gradient(d_loss, discriminator.trainable_variables)\n",
    "    D_optimizer.apply_gradients(zip(D_gradients, discriminator.trainable_variables))\n",
    "    \n",
    "    if step % 10 == 0:\n",
    "        with file_writer.as_default():\n",
    "            tf.summary.scalar('D_loss', tf.reduce_mean(d_loss), step=step)\n",
    "    \n",
    "    return d_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input, expected_output, figure_size=(12,6), subplot=(3,6), save=True, show=False):\n",
    "    '''\n",
    "        Generate images and plot it.\n",
    "    '''\n",
    "    rows = subplot[0]\n",
    "    columns = subplot[1]\n",
    "\n",
    "    predictions = model(test_input, training=False) \n",
    "    fig, axs = plt.subplots(rows, columns, figsize=figure_size, gridspec_kw={'width_ratios':[1 for x in range(columns)], 'height_ratios':[1 for x in range(rows)]})\n",
    "    fig.subplots_adjust(top=0.4)\n",
    "    \n",
    "    for row in range(rows):\n",
    "        for column in range(columns):\n",
    "            i = column\n",
    "            if row == 0:\n",
    "                # y\n",
    "                axs[row, column].set_title('GroundTruth') if i == columns//2 else None\n",
    "                axs[row, column].imshow(expected_output[i])\n",
    "            elif row == 1:\n",
    "                # predict\n",
    "                axs[row, column].set_title('Output') if i == columns//2 else None\n",
    "                axs[row, column].imshow(predictions[i])\n",
    "            else:\n",
    "                # x\n",
    "                axs[row, column].set_title('Input') if i == columns//2 else None\n",
    "                axs[row, column].imshow(test_input[i])\n",
    "            axs[row, column].axis('off')\n",
    "    \n",
    "    ssim = tf.math.reduce_mean(ssim_metric(expected_output, predictions, max_val=1.))\n",
    "    psnrb_v = tf.math.reduce_mean(psnrb(expected_output, predictions))\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(\"ssim:%.5f, psnrb: %.5f\" %(ssim, psnrb_v), y=1)\n",
    "            \n",
    "    del fig, axs\n",
    "    if save:\n",
    "        plt.savefig(os.path.join(OUTPUT_PATH, 'image_at_epoch_{:04d}.png'.format(epoch)))\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples_to_generate = 7\n",
    "\n",
    "# change y_test for x_test\n",
    "magic_number = [rd.randint(0, x_test.shape[0]-1) for x in range(num_examples_to_generate)]\n",
    "\n",
    "assert y_test.shape == x_test.shape\n",
    "sample = np.array([x_test[idx] for idx in magic_number])\n",
    "answer = np.array([y_test[idx] for idx in magic_number])\n",
    "\n",
    "generate_and_save_images(generator, 0, sample, answer, figure_size=(12,6), subplot=(3, num_examples_to_generate), save=False, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(\"checkpoints\", \"tensorflow\", MODEL_NAME)\n",
    "\n",
    "ckpt = tf.train.Checkpoint(generator=generator,\n",
    "                           discriminator=discriminator,\n",
    "                           G_optimizer=G_optimizer,\n",
    "                           D_optimizer=D_optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint.\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    latest_epoch = int(ckpt_manager.latest_checkpoint.split('-')[1])\n",
    "    CURRENT_EPOCH = latest_epoch * SAVE_EVERY_N_EPOCH\n",
    "    print ('Latest checkpoint of epoch {} restored!!'.format(CURRENT_EPOCH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_critic_count = 0\n",
    "ssim = -1\n",
    "psnrb_v = 0\n",
    "D_loss = 1\n",
    "G_loss = 1\n",
    "for epoch in range(CURRENT_EPOCH, N_EPOCHS+1):\n",
    "    print()\n",
    "    with tqdm(total=len(y_train_batches)) as pbar:\n",
    "        for step ,(training_batch, groundtruth_batch) in enumerate(zip(x_train_batches, y_train_batches)):\n",
    "            D_loss = D_train_step(training_batch, groundtruth_batch)\n",
    "            n_critic_count+=1\n",
    "            \n",
    "            if n_critic_count >= N_CRITIC:\n",
    "                G_loss = G_train_step(training_batch, groundtruth_batch)\n",
    "                n_critic_cout = 0\n",
    "    \n",
    "            if epoch % SAVE_EVERY_N_EPOCH == 0:\n",
    "                ckpt_save_path = ckpt_manager.save()\n",
    "                generate_and_save_images(generator, epoch, sample, answer, figure_size=(12,6), subplot=(3,6), save=True)\n",
    "            \n",
    "            if step % VAL_EVERY_N_STEPS == 0:\n",
    "                for idx, (x, y) in enumerate(zip(x_test_batches, y_test_batches)):\n",
    "\n",
    "                    images_out = generator(x, training=False)\n",
    "\n",
    "                    ssim = tf.math.reduce_mean(ssim_metric(y, images_out, max_val=1.))\n",
    "                    psnrb_v = tf.math.reduce_mean(psnrb(y, images_out))\n",
    "                    with file_writer.as_default():\n",
    "                        tf.summary.scalar('psnrb_val', tf.reduce_mean(psnrb_v), step=step)\n",
    "                        tf.summary.scalar('ssim_val', tf.reduce_mean(ssim), step=step)\n",
    "                \n",
    "            pbar.set_description(\"Epoch %d/%d: \" %(epoch+1, N_EPOCHS))\n",
    "            pbar.write(\"G_loss: %.5f, D_loss: %.5f, ssim_val: %.5f, ssim_val: %.5f\" %(G_loss, D_loss, ssim, psnrb_v))\n",
    "            pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
