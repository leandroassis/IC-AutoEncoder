{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sys import path\n",
    "from os import getcwd\n",
    "\n",
    "path.insert(getcwd() + '../modules/') # adding modules folder to path\n",
    "\n",
    "from modules.DataMod import DataSet\n",
    "from modules.TrainingManager import KerasTrainingManager\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the datasets\n",
    "tinyDataSet = DataSet.load_rafael_tinyImagenet_64x64_noise_data()\n",
    "cifarDataSet = DataSet.load_rafael_cifar_10_noise_data()\n",
    "cifarAndTinyDataSet = DataSet.concatenateDataSets(cifarDataSet, tinyDataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the training managers\n",
    "\n",
    "# to do: paralelize the training (does it's necessary?)\n",
    "\n",
    "# uNet\n",
    "uNet_tiny_Manager = KerasTrainingManager(\n",
    "    \"uNet_tiny\",\n",
    "    optimizer = Adam,\n",
    "    optimizer_kwargs = {'learning_rate' : 0.001, 'beta_1' : 0.9, 'beta_2' : 0.999, 'epsilon' : 1e-7, 'amsgrad' : False},\n",
    "    loss = LossLinearCombination,\n",
    "    loss_kwargs = {'losses' : [AdversarialLoss, MeanAbsoluteError], 'weights' : [1,1], 'bias_vector' : [0,0]},\n",
    "    compile_kwargs = {'loss_weights' : None, 'weighted_metrics' : None, 'run_eagerly' : None, 'steps_per_execution' : None},\n",
    "    \n",
    "    fit_kwargs = {'batch_size' : 20, 'epochs' : 20, 'verbose':1, 'validation_split':0, 'shuffle':True, \n",
    "    'class_weight':None, 'sample_weight':None, 'steps_per_epoch':None, 'validation_steps':None, \n",
    "    'validation_batch_size':None, 'validation_freq':1, 'max_queue_size':10, 'workers':1, 'use_multiprocessing':False},\n",
    "\n",
    "    metrics = [ssim_metric],\n",
    "\n",
    "    training_function = generator_training,\n",
    "\n",
    "    dataset = tinyDataSet\n",
    "\n",
    ")\n",
    "uNet_cifar_Manager = KerasTrainingManager(\"uNet_cifar\")\n",
    "uNet_cifarAndTiny_Manager = KerasTrainingManager(\"uNet_cifarAndTiny\")\n",
    "\n",
    "# autoencoder\n",
    "autoencoder_tiny_Manager = KerasTrainingManager(\"autoencoder_tiny\")\n",
    "autoencoder_cifar_Manager = KerasTrainingManager(\"autoencoder_cifar\")\n",
    "autoencoder_cifarAndTiny_Manager = KerasTrainingManager(\"autoencoder_cifarAndTiny\")\n",
    "\n",
    "# residual autoencoder\n",
    "residual_autoencoder_tiny_Manager = KerasTrainingManager(\"residual_autoencoder_tiny\")\n",
    "residual_autoencoder_cifar_Manager = KerasTrainingManager(\"residual_autoencoder_cifar\")\n",
    "residual_autoencoder_cifarAndTiny_Manager = KerasTrainingManager(\"residual_autoencoder_cifarAndTiny\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
